# -*- coding: utf-8 -*-
"""82015-AiDev-Clase-02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QFe03gFdXm3Qv33lsUldTRsG5PxqdHJ4
"""

print("Hola Mundo")

"""# Ejemplo llamada a Groq"""

!pip install groq

from groq import Groq

api_key = input("Ingrese su Api Key")
prompt = input("Ingrese su prompt")

client = Groq(api_key=api_key)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": prompt
        }
    ],
    model="moonshotai/kimi-k2-instruct",
    stream=False,
)

print(chat_completion.choices[0].message.content)

"""# LA IA que se programa a si misma (Onda Black Mirror)

"""

from groq import Groq

api_key = input("Ingrese su Api Key")

client = Groq(api_key=api_key)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role":"system",
            "content":"Eres un programador senior experto en python"
        },
        {
            "role": "user",
            "content": "Generar un codigo en pyton que muestra los numeros del 1 al 10. Devuelve solamente el codigo sin acotar nada mas. No devolver markdown. Solo texto"
        }
    ],
    model="moonshotai/kimi-k2-instruct",
    stream=False,
)

codigo_python = chat_completion.choices[0].message.content
print(codigo_python)
exec(codigo_python)

"""# Vamos a darle una interfaz a la IA con Gradio"""

!pip install gradio

import gradio as gr
from groq import Groq

# Variable global para almacenar la API key del usuario
client = None

def set_api_key(api_key):
    global client
    try:
        client = Groq(api_key=api_key)
        return "‚úÖ API Key configurada correctamente"
    except Exception as e:
        return f"‚ùå Error al configurar la API Key: {e}"

def chatbot_interface(message, history):
    if not client:
        return "‚ö†Ô∏è Primero debes ingresar tu API Key arriba.", history

    try:
        # Construye el historial en el formato requerido por la API
        messages = [{"role": "user" if i % 2 == 0 else "assistant", "content": m} for i, (m, _) in enumerate(history)]
        messages.append({"role": "user", "content": message})

        response = client.chat.completions.create(
            messages=messages,
            model="moonshotai/kimi-k2-instruct",
            stream=False,
        )
        reply = response.choices[0].message.content
        history.append((message, reply))
        return "", history
    except Exception as e:
        return f"‚ùå Error al conectar con Groq: {e}", history


# UI de Gradio
with gr.Blocks(title="Groq Chatbot") as demo:
    gr.Markdown("## ü§ñ Chatbot con Groq API (Modelo Kimi K2)")

    with gr.Row():
        api_input = gr.Textbox(label="üîë Ingres√° tu API Key", type="password")
        set_key_btn = gr.Button("Guardar API Key")
        status_output = gr.Textbox(label="Estado", interactive=False)

    set_key_btn.click(fn=set_api_key, inputs=api_input, outputs=status_output)

    chatbot = gr.Chatbot(label="Chat estilo ChatGPT")
    msg = gr.Textbox(label="Escrib√≠ tu mensaje")
    send_btn = gr.Button("Enviar")

    send_btn.click(fn=chatbot_interface, inputs=[msg, chatbot], outputs=[msg, chatbot])

demo.launch()

"""# Utilizar modelos descargados de Hugging Face en Google Colab"""

!pip install -q transformers

# ‚úÖ Instalamos transformers (de Hugging Face)
!pip install -q transformers

# ‚úÖ Importamos pipeline desde Hugging Face
from transformers import pipeline

# ‚úÖ Cargamos el modelo distilgpt2, que es liviano y funciona bien
generator = pipeline("text-generation", model="distilgpt2")

# ‚úÖ Prompt base
prompt = "La inteligencia artificial cambiar√° el mundo porque"

# ‚úÖ Generamos texto
result = generator(prompt, max_length=50, num_return_sequences=1)

# ‚úÖ Mostramos la salida generada
print()
print()
print(result[0]["generated_text"])