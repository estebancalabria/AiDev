# **Resumen de la Reunión**

## **Introducción**

La reunión comenzó con una breve introducción sobre el uso de herramientas de inteligencia artificial, específicamente en el contexto de la creación de scorecards para entrevistas. Se discutió la importancia de estructurar la información obtenida durante las entrevistas para facilitar la evaluación de candidatos.

## **Proceso de Creación de Scorecards**

* **Notas de Entrevista**: Se mencionó que se toman notas durante las entrevistas, las cuales son fundamentales para completar el scorecard.  
* **Uso de Datos**: Se enfatizó que todos los ítems del scorecard deben ser respondidos con información verificada. Si no se cuenta con información suficiente, se debe indicar que se necesita más datos.  
* **Carga de Información**: Se explicó el proceso de cargar el CV del candidato y las notas de la entrevista en el sistema para generar el scorecard.

## **Herramientas de Traducción y Búsqueda**

* Se discutió la necesidad de traducir términos entre inglés y español durante las entrevistas, y cómo el sistema puede ayudar a evitar confusiones.  
* Se mencionó que el sistema tiene la capacidad de buscar información en LinkedIn y otras fuentes en línea para validar datos sobre los candidatos.

## **Configuración del Sistema**

* Se abordó la importancia de la configuración del sistema para manejar múltiples interacciones sin perder contexto. Se sugirió aumentar el número de interacciones que el sistema puede recordar.  
* Se explicó la diferencia entre el uso de herramientas externas y la configuración del modelo para optimizar su rendimiento.

## **Mejora de Scorecards Culturales**

* Se discutió la mejora de los scorecards culturales, alineándolos con estándares de calidad como los de la ISO.  
* Se mencionaron competencias clave como trabajo en equipo y liderazgo, y cómo estas se integran en el proceso de evaluación.

## **Uso de Modelos de Lenguaje**

* Se presentó el nuevo modelo Lama 3.2, destacando su capacidad de procesamiento y la incorporación de visión por computadora.  
* Se discutió la importancia de dividir prompts largos en partes más manejables para facilitar el procesamiento por parte del modelo.

## **Laboratorio Práctico**

* Se llevó a cabo un laboratorio donde se instaló el modelo Lama en Google Colab. Se discutieron los pasos para ejecutar el modelo y se realizaron pruebas de rendimiento.  
* Se explicó cómo usar Gradio para crear interfaces web para interactuar con el modelo.

## **Resumen de Textos Largos**

* Se presentó un método para resumir textos largos utilizando el modelo Lama, dividiendo el texto en "chunks" para facilitar su procesamiento.  
* Se propuso usar un cuento de Borges como ejemplo para demostrar la capacidad del modelo para resumir textos extensos.

## **Conclusiones**

* Se destacó la utilidad de las herramientas de inteligencia artificial en el proceso de reclutamiento y evaluación de candidatos.  
* Se acordó continuar explorando el uso de estas tecnologías en futuras reuniones y laboratorios.

## **Cierre**

La reunión finalizó con agradecimientos y la promesa de seguir trabajando en la implementación de estas herramientas en los procesos de selección y evaluación. Se programó una próxima reunión para continuar con el desarrollo de estas iniciativas.

